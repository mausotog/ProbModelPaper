Other CLG thoughts:

The two-level model would be improved if the insertions model were also weighted
probabilistically; the evaluation would be improved if it actually broke down
the full predictive success based on both models together.

Really, we need more real bugs in the evaluation.  In a perfect world, we'd
remove the case study subsection entirely and just have a proper evaluation of
model success on their own, and then repair success using the models (and with
held out test cases), comparing success/quality to the GenProg (or PAR) produced
patches.

One possibility in place of the case study is to run the model version of repair
on the IntroClass for Java benchmarks produced by Martin Monperrus and his group
because those held-out test suites are better.  However, it's not obvious to me
what the result would be (given that we learn the probabilities on real world
code and IntroClass4Java is small student programs).


Original Mau Todos:

(2) This study needs to clearly define evaluation measures to show how and why
using probabilistic models are better to find better mutation operator to
improve APR approach. For example, is there any measure to show how the search
space was reduced after using the models? Does the proposed approach reduce more
search space compared with the existing approaches such as [8] and [31]? How
could the number of variants be a measure in what sense?

	The search space is not reduced in number of variants. But it is reduced in
	the sense that the variants created are more likely to be correct, 

    --CLG: this is an interesting claim that we don't necessarily directly
      evaluate.  But we could, in the spirit of Fan Long and Martin Rinard's
      weird ICSE 2016 paper.  That is: for a set of (real) bugs, enumerate the
      first 100 proposed patches for each bug according to eahc technique.  See
      how many are "plausible" (pass all test case) versus "correct" (pass held
      out test cases). 

    therefore
	we don't have to traverse so much of the search space because the search
	space that we are creating is already close to the solution, and this is
	reflected by the fact that we found the patch faster.


(2) Does the smaller number of variants means that the patches can be found
faster? Howe much faster? With the current experimental setting and
interpretation of results, it is difficult to say using probabilistic model is
faster in what sense.

	Consider instead of writting the number of variants it takes to find a
	patch, to write the percentage of time faster/slower. For example: instead
	of 20 variants against 10 variants. Say 50% faster.
    
    --CLG: I don't really like percentage improvements but if we report both,
      that's fine. 



(3) The association rule analysis, while interesting and certainly useful, does
not fit with the theme of this paper. I would recommend either: (a) removing it
or (b) spending more effort to explain how the analysis fit together to solve
one common problem. It currently stands out as a tangential analysis that
doesn't really contribute to the main message of the paper.

	I actually like this section a lot, although I do see why the reviewer makes
	this point. I need to blend it more into the story of the paper.



	
	
	
	
	
	
	
	
	
	
	
	
	
	
